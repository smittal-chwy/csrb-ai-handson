{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9769c4a0",
   "metadata": {},
   "source": [
    "# Intro\n",
    "- In this notebook we are connecting to hugging-face(hf) and loading model from hf.\n",
    "- hf pipeline is created\n",
    "- text geneation is implemented usig the hf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50971fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/smittal/sandbox/csrb-ai-handson/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3600ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers                             4.56.1\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c40ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (4.56.1)\n",
      "Requirement already satisfied: accelerate in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: torch in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: filelock in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: psutil in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers accelerate torch python-dotenv\n",
    "# or run requirements.txt from root `CSRB-AI-HANDSON/` for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496539e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smittal/sandbox/csrb-ai-handson/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6c3d8",
   "metadata": {},
   "source": [
    "## Either load env params from .env script or load directly in notebook. As shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load from env file\n",
    "\n",
    "# load_dotenv()\n",
    "# hf_token = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99100290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in notebook cell env params: \n",
    "\n",
    "# Hugging Face\n",
    "HF_TOKEN=\"hf_\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c533f",
   "metadata": {},
   "source": [
    "## Below cell:\n",
    "- Creates a pipeline for text generation.\n",
    "- Loads the distilgpt2 or gpt2 or any other model which can be loded.\n",
    "- The token parameter passes authentication (optional here).\n",
    "\n",
    "### Small, Lightweight Models (CPU-friendly)\n",
    "- Good for demos, hands-on labs, and laptops.\n",
    "  - distilgpt2 → small GPT-2 variant for text generation.\n",
    "  - gpt2 → the original GPT-2 (bigger than distil).\n",
    "  - facebook/bart-base → good for summarization.\n",
    "  - t5-small → great for text-to-text tasks (translation, summarization).\n",
    "  - sentence-transformers/all-MiniLM-L6-v2 → embeddings for search/RAG.\n",
    "\n",
    "### Instruction-Tuned Open LLMs (need GPU)\n",
    "- These are trained to follow instructions (like ChatGPT-style).\n",
    "  - mistralai/Mistral-7B-Instruct-v0.2\n",
    "  - tiiuae/falcon-7b-instruct\n",
    "  - meta-llama/Llama-2-7b-chat-hf (requires accepting license & HF token).\n",
    "  - google/flan-t5-base (smaller, runs on CPU/GPU).\n",
    "\n",
    "### and many more....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b1f10df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebb8fc23d4244e2a6296873560210f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5b6be9f9ed4a7eae8ec8b0484ab8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d9280f18674cf7a6d6acf1912076d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89a59fae2494a43aee6eb5cdf985fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402e2d0b245f476b99e83eddc02bcbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3756a2d0b24cd897f3a44c9b510e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1655f3cd574222a2a34fb7a378fc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt2\" # \"distilgpt2\" \n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, token=HF_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "037938d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query0= \"A short story on a person who designed bitcoin algorithm\"\n",
    "query1= \"A good detailed description on an anime `one piece` with proper plot and characters in a fomatted bulleted list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab615043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "max_length=256 → sets the maximum number of tokens (words + subwords) in the generated output (including the prompt).\n",
    "num_return_sequences=1 → tells the model to return only one completion instead of multiple alternatives.\n",
    "\"\"\"\n",
    "result = generator(query1, \n",
    "                   max_length=256, \n",
    "                   num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f7c9bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A good detailed description on an anime `one piece` with proper plot and characters in a fomatted bulleted list would be nice. If there are more details on the book, please give it a read.\n",
      "\n",
      "\n",
      "The novel is told from the point of view of the heroine Kirina, who is a \"living\" person whose life is at stake. Kirina is a single woman who is constantly under the impression that life is a dangerous one in Japan. She has an extremely low level of understanding of the importance of her life and her role in society. She seems to have been a victim of an extremely cruel and abusive father and the only one who can change her.\n",
      "\n",
      "\n",
      "The novel does not have any significant plot points, but it does have a good story and character development. Helpful the main character Kirina's father is a young girl with very small brains, who is a member of the \"Wakizashi family\". Kirina has been involved with her father for years. She has become quite the victim of a very cruel and abusive father. Kirina, who is a living person on the verge of death, is the one who must be dealt with. It's not a book where the plot is clear, but rather a series of events that lead up to her death. The events that take place are very detailed and interesting.The plot is well developed and the\n"
     ]
    }
   ],
   "source": [
    "print(result[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
